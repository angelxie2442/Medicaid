{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created on 4/2/2020\n",
    "Author: Yuan-Chi Yang\n",
    "\n",
    "Objective: template for content analysis on political feedback, please feel free to modify and play around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data and perform some checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is from \"C:\\Users\\yyang60\\PostDoct-Emory\\medicaid-project\\medicaid-classifier\\labeling-data\\whole_dataset\\BERT_20200228\\political-tweets-streaming.csv\"\n",
    "\n",
    "It consists of all the tweets classified as the 'p' class by the best performing classfiers to date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./political-tweets-streaming.csv',header = 0, keep_default_na=False,dtype={'tweet_id':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "383969"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['tweet_id', 'unprocessed_text', 'class'], dtype='object')"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Duplicates\n",
    "No Duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated(subset = ['tweet_id'], keep=False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include 'text_remove_stopwords' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadStopWords(FILENAME):\n",
    "    stopword_list = []\n",
    "    infile = open(FILENAME)\n",
    "    for line in infile:\n",
    "        stopword_list.append(line.strip())\n",
    "    print(len(stopword_list))\n",
    "    return stopword_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_text_remove_stopwords(tweet_text,stop_words):\n",
    "    tweet_text = re.sub(r'&amp;', \"and\", tweet_text)\n",
    "    tweet_text = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '',\n",
    "                        tweet_text)\n",
    "    #tweet_text = re.sub('(@[A-Za-z0-9\\_]+)', '', tweet_text)\n",
    "    tweet_text = re.sub('(@[\\S]+)', '', tweet_text)#added Angel\n",
    "    ####the following section separate words following each hashtag\n",
    "    list_hashtag1=re.findall('(#[\\S]+)',tweet_text)\n",
    "    list_hashtag2=[]\n",
    "    for p in list_hashtag1:\n",
    "        p=re.sub('(#)',' ',p)#clear hashtag symbols\n",
    "        p1=re.findall('([A-Z]{2,})',p)#uppercase abbrevs\n",
    "        for p2 in p1:\n",
    "            list_hashtag2.append(p2)#add abbrevs\n",
    "        p=re.sub('([A-Z]{2,})',' ',p)#clear uppercase abbrevs\n",
    "        p1=re.findall('([A-Z][a-z]{1,})',p)#words start uppercase letter\n",
    "        for p2 in p1:\n",
    "            list_hashtag2.append(p2)\n",
    "        p=re.sub('([A-Z][a-z]{1,})',' ',p)#clear words start with uppercase letter\n",
    "        p=re.sub('([A-Z])',' ',p)#clear single uppercase letters\n",
    "        p=re.sub('([^A-Za-z])',' ',p)#clear symbols\n",
    "        p1=p.split()#find leftover words\n",
    "        for p2 in p1:\n",
    "            list_hashtag2.append(p2)#add leftover words\n",
    "    tweet_text=re.sub('(#[\\S]+)','',tweet_text)\n",
    "    \n",
    "    tweet_text = re.sub(\"[^a-zA-Z_-]\", \" \", tweet_text)\n",
    "    tweet_text = tweet_text.lower()\n",
    "    tweet_text = re.sub(r'\\s{2,}', \" \", tweet_text)\n",
    "    list_hashtag= [h for h in list_hashtag2 if (not h in stop_words and len(h)>1)]\n",
    "    tweet_text = [t for t in tweet_text.split() if (not t in stop_words and len(t)>1)]\n",
    "    tweet_text.extend(list_hashtag)\n",
    "    return ' '.join(tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261\n"
     ]
    }
   ],
   "source": [
    "stopwords = set(loadStopWords('./stopwords.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_remove_stopwords'] = df['unprocessed_text'].apply(lambda x: processing_text_remove_stopwords(x,stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the most frequent words in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams = ' '.join(df['text_remove_stopwords'].to_list()).split()\n",
    "bigrams = []\n",
    "for tweet in df['text_remove_stopwords'].to_list():\n",
    "    bigrams += list(nltk.bigrams(tweet.split()))\n",
    "    \n",
    "trigrams = []\n",
    "for tweet in df['text_remove_stopwords'].to_list():\n",
    "    trigrams += list(nltk.trigrams(tweet.split()))\n",
    "uni_fd = nltk.FreqDist(unigrams)\n",
    "big_fd = nltk.FreqDist(bigrams)\n",
    "trig_fd = nltk.FreqDist(trigrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigrams:\n",
      "\n",
      "people 66954\n",
      "social 64162\n",
      "security 59281\n",
      "care 51287\n",
      "get 48687\n",
      "health 41356\n",
      "would 40135\n",
      "pay 39945\n",
      "insurance 39921\n",
      "trump 39077\n",
      "healthcare 38641\n",
      "expansion 38198\n",
      "like 35822\n",
      "cut 30612\n",
      "tax 29473\n",
      "state 29422\n",
      "cuts 28059\n",
      "need 26424\n",
      "want 26282\n",
      "food 23709\n",
      "work 23698\n",
      "programs 23589\n",
      "us 23326\n",
      "re 23125\n",
      "money 22908\n",
      "states 21239\n",
      "aca 20763\n",
      "free 20572\n",
      "one 19826\n",
      "know 19507\n",
      "also 19277\n",
      "take 19129\n",
      "government 19113\n",
      "poor 19012\n",
      "public 18829\n",
      "many 18774\n",
      "stamps 18513\n",
      "budget 18252\n",
      "coverage 17871\n",
      "make 17382\n",
      "--------------------------------------------------------\n",
      "\n",
      "bigrams:\n",
      "\n",
      "social security 56343\n",
      "food stamps 18233\n",
      "health care 16441\n",
      "health insurance 8651\n",
      "tax cuts 6999\n",
      "private insurance 5939\n",
      "cut social 5701\n",
      "cuts social 4495\n",
      "take away 4110\n",
      "work requirements 3636\n",
      "middle class 3528\n",
      "low income 3129\n",
      "mental health 3037\n",
      "budget cuts 2976\n",
      "pre-existing conditions 2964\n",
      "Medicare Medicaid 2922\n",
      "trump budget 2918\n",
      "For All 2791\n",
      "insurance companies 2751\n",
      "tax cut 2736\n",
      "poor people 2705\n",
      "public schools 2632\n",
      "get rid 2495\n",
      "programs like 2474\n",
      "public option 2438\n",
      "Medicare For 2408\n",
      "social programs 2325\n",
      "minimum wage 2323\n",
      "Social Security 2272\n",
      "illegal immigrants 2250\n",
      "single payer 2231\n",
      "affordable care 2142\n",
      "medical care 2126\n",
      "care act 2098\n",
      "safety net 2073\n",
      "tax dollars 2067\n",
      "planned parenthood 2002\n",
      "wants cut 1980\n",
      "rural hospitals 1951\n",
      "socialist programs 1940\n",
      "--------------------------------------------------------\n",
      "\n",
      "trigrams:\n",
      "\n",
      "cut social security 5471\n",
      "cuts social security 4336\n",
      "Medicare For All 2373\n",
      "affordable care act 1923\n",
      "cutting social security 1787\n",
      "welfare food stamps 1683\n",
      "billion social security 1550\n",
      "like social security 1428\n",
      "GOPT Scam ax 1289\n",
      "tax cuts rich 1060\n",
      "social security food 1056\n",
      "social security public 1037\n",
      "social security pay 1001\n",
      "Save Our Seniors 972\n",
      "food stamps housing 966\n",
      "Protect Our Care 925\n",
      "security food stamps 924\n",
      "social security budget 905\n",
      "get food stamps 889\n",
      "social security etc 873\n",
      "social security cuts 832\n",
      "food stamps etc 822\n",
      "away social security 785\n",
      "social security disability 773\n",
      "trillion billion billion 762\n",
      "said wouldn cut 755\n",
      "healthcare social security 731\n",
      "wouldn cut social 725\n",
      "Social Security Medicare 723\n",
      "trump budget cuts 715\n",
      "protect social security 704\n",
      "trump said wouldn 701\n",
      "private health insurance 696\n",
      "universal health care 693\n",
      "social security snap 677\n",
      "food stamps welfare 667\n",
      "social security billion 655\n",
      "tax cuts wealthy 645\n",
      "pay tax cuts 640\n",
      "billion billion social 638\n"
     ]
    }
   ],
   "source": [
    "def wordInNumTweets(term):\n",
    "    pattern = rf'(^|[^a-zA-Z]){term}([^a-zA-Z]|$)' #rf is for using a variable inside\n",
    "    count=0;\n",
    "    for i in range(len(df['text_remove_stopwords'])):\n",
    "         if(re.search(pattern,df['text_remove_stopwords'].iloc[i])!=None):\n",
    "            count=count+1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num = 40\n",
    "print('unigrams:\\n')\n",
    "fd = uni_fd\n",
    "fd_list = [(x,fd[x]) for x in fd]\n",
    "fd_list.sort(key = lambda x: x[1], reverse = True)\n",
    "df_uni=[]\n",
    "for i in range(0,num):\n",
    "    print(fd_list[i][0], fd_list[i][1])\n",
    "    df_uni['term']=fd_list[i][0]\n",
    "    df_uni['counts']=fd_list[i][1]\n",
    "    df_uni['num_of_tweets']=\n",
    "\n",
    "    \n",
    "print('--------------------------------------------------------\\n')\n",
    "    \n",
    "print('bigrams:\\n')\n",
    "fd = big_fd\n",
    "fd_list = [(x,fd[x]) for x in fd]\n",
    "fd_list.sort(key = lambda x: x[1], reverse = True)\n",
    "for i in range(0,num):\n",
    "    x, y= fd_list[i][0]\n",
    "    term = x + ' '+ y\n",
    "    print(term, fd_list[i][1])\n",
    "\n",
    "print('--------------------------------------------------------\\n')\n",
    "print('trigrams:\\n')\n",
    "\n",
    "fd = trig_fd\n",
    "fd_list = [(x,fd[x]) for x in fd]\n",
    "fd_list.sort(key = lambda x: x[1], reverse = True)\n",
    "for i in range(0,num):\n",
    "    x, y, z= fd_list[i][0]\n",
    "    term = x + ' '+ y + ' ' + z\n",
    "    print(term, fd_list[i][1])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the interesting terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highfreqword(text,term):\n",
    "    pattern = rf'(^|[^a-zA-Z]){term}([^a-zA-Z]|$)' #rf is for using a variable inside\n",
    "    #pattern = rf'{term}'\n",
    "    if(re.search(pattern,text)!=None):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bigrams_ls=['social security','mental health','healthcare','insurance','food stamps','health care','health insurance','private insurance','cuts social','take away','work requirements','trump budget','pre-existing conditions','insurance companies','expansion','budget cuts']\n",
    "for i in range(16):\n",
    "    coln=bigrams_ls[i]\n",
    "    df[coln] = df['text_remove_stopwords'].apply(lambda x:highfreqword(x,coln))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "data": {
      "text/plain": "3382"
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp=df[df['middle class'].apply(lambda x:x==1)]\n",
    "len(df_temp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-132-7e03087d1343>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_temp1=df_temp[df[bigrams_ls[i]].apply(lambda x:x==1)]\n",
      "<ipython-input-132-7e03087d1343>:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_temp1=df_temp[df['healthcare'].apply(lambda x:x==1)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "862\n",
      "11\n",
      "458\n",
      "385\n",
      "125\n",
      "157\n",
      "100\n",
      "47\n",
      "108\n",
      "75\n",
      "8\n",
      "31\n",
      "43\n",
      "18\n",
      "144\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "for i in range(16):\n",
    "    df_temp1=df_temp[df[bigrams_ls[i]].apply(lambda x:x==1)]\n",
    "    print(len(df_temp1))\n",
    "df_temp1=df_temp[df['healthcare'].apply(lambda x:x==1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "#term2 = 'trump budget'\n",
    "#pattern = rf'(^|[^a-zA-Z]){term2}([^a-zA-Z]|$)' #rf is for using a variable inside\n",
    "#df_temp2 = df[df['text_remove_stopwords'].apply(lambda x: re.search(pattern,x)!=None)]\n",
    "#print('# of tweets:',len(df_temp2))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of duplicated tweets: 0\n"
     ]
    }
   ],
   "source": [
    "#df_temp12 =df_temp1.append(df_temp2)\n",
    "#print('# of duplicated tweets:',df_temp12.duplicated(subset = ['tweet_id'], keep=False).sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "num = 30\n",
    "temp = df_temp1.sample(n=num)\n",
    "#for i in range(0,num):\n",
    "    #print(temp['unprocessed_text'].iloc[i],'\\n\\n')\n",
    "    #print(temp['text_remove_stopwords'].iloc[i],'\\n\\n')\n",
    "    #print('---------------------------------------------------------------------------------')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp.to_csv('ss_pec_sample.csv')\n",
    "#temp.to_csv('mh_e_sample.csv')\n",
    "temp.to_csv('mc_h_sample.csv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}